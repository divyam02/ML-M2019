Q1. Training accuracy for L1: ~ 0.80
	Training accuracy for L2: ~ 0.75

	Validation accuracy for L1 ~ 0.42  
	Validation accuracy for L2 ~ 0.45
	
	Testing accuracy for L1 ~ 0.30
	Testing accuracy for L2 ~ 0.35

	L1 regularization is performing better during training in this dataset
	despite high variance (outliers) is due to it giving the same weight 
	update for higher or smaller losses. This makes it robust to noisy data 
	as provided here (which has 105 features and most values as sparse after
	preprocessing).

	However L2 regularization ends up performing better during testing because 
	it is sensitive to outliers and updates weights proportional to the sample
	feature values. As such, this allows it to be more robust to unseen data 
	which might be in the outlier region.

Q2. Using Stochastic Averaged Gradient method because of sparse matrices!

	L1 training accuracy: 0.889
	L1 testing accuracy: 0.892

	L2 training accuracy: 0.889
	L2 testing accuracy: 0.89